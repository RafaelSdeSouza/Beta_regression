localH2O
h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=4)
library(h2o)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=-1)
irisPath = system.file("extdata", "iris.csv", package = "h2o")
iris.hex = h2o.importFile(localH2O, path = irisPath)
h2o.deeplearning(x = 1:4, y = 5, data = iris.hex, activation = "Tanh",
hidden = c(10, 10), epochs = 5)
h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '16g',nthreads=-1)
localH2O = h2o.init(ip = "localhost", port = 54321, startH2O = TRUE,
max_mem_size = '32g',nthreads=-1)
irisPath = system.file("extdata", "iris.csv", package = "h2o")
iris.hex = h2o.importFile(localH2O, path = irisPath)
h2o.deeplearning(x = 1:4, y = 5, data = iris.hex, activation = "Tanh",
hidden = c(10, 10), epochs = 5)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/NB_GCs/Models_each_predictor")
#Poisson and NB regression using JAGS by Rafael S. de Souza, Bart Buelens, Ewan Cameron
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
require(runjags)
# Function to allow parse labels in facet_wrap
facet_wrap_labeller <- function(gg.plot,labels=NULL) {
#works with R 3.0.1 and ggplot2 0.9.3.1
require(gridExtra)
g <- ggplotGrob(gg.plot)
gg <- g$grobs
strips <- grep("strip_t", names(gg))
for(ii in seq_along(labels))  {
modgrob <- getGrob(gg[[strips[ii]]], "strip.text",
grep=TRUE, global=TRUE)
gg[[strips[ii]]]$children[[modgrob$name]] <- editGrob(modgrob,label=labels[ii])
}
g$grobs <- gg
class(g) = c("arrange", "ggplot",class(g))
g
}
give.n <- function(x){
return(c(y = 0.5, label = length(x)))
# experiment with the multiplier to find the perfect position
}
################
# Script starts here
# Read data
GCS = read.csv(file="..//Dataset//GCs_full.csv",header=TRUE,dec=".",sep="")
GCS = subset(GCS, !is.na(MV_T))
#dim(GCS)
N_err<-GCS$N_GC_err
err_MV_T<-GCS$err_MV_T
N = nrow(GCS)
######## NB with errors ########################################################
MV_Tx = seq(from = 1.05 * min(GCS$MV_T),
to = 0.95 * max(GCS$MV_T),
length.out = 500)
jags.data <- list(
N_GC = GCS$N_GC,
MV_T = GCS$MV_T,
errN_GC = GCS$N_GC_err,
N = nrow(GCS),
err_MV_T = err_MV_T,
MV_Tx = MV_Tx,
M = 500
)
model.NB <- "model{
# Priors for regression coefficients
beta.0~dnorm(0,0.000001)
beta.1~dnorm(0,0.000001)
# Prior for size
size~dunif(0.001,5)
#
for (i in 1:N){
MV_T_true[i]~dunif(-26,-10)
}
# Likelihood function
for (i in 1:N){
MV_T[i]~dnorm(MV_T_true[i],1/err_MV_T[i]^2);
errorN[i]~dbin(0.5,2*errN_GC[i])
eta[i]<-beta.0+beta.1*MV_T_true[i]
#log(mu[i])<-max(-20,min(20,eta[i]))# Ensures that large beta values do not cause numerical problems.
log(mu[i])<-log(exp(eta[i])+errorN[i]-errN_GC[i])
p[i]<-size/(size+mu[i])
N_GC[i]~dnegbin(p[i],size)
# Prediction
etaTrue[i]<-beta.0+beta.1*MV_T_true[i]
log(muTrue[i])<-max(-20,min(20,etaTrue[i]))
pTrue[i]<-size/(size+muTrue[i])
prediction.NB[i]~dnegbin(pTrue[i],size)
#prediction.NB[i]~dnegbin(p[i],size)
# Discrepancy measures
YNew[i] ~ dnegbin(p[i],size)
expY[i] <- mu[i]
varY[i] <- mu[i] + pow(mu[i],2) / size
PRes[i] <-(N_GC[i] - expY[i])/sqrt(varY[i])
PResNew[i] <-(YNew[i] - expY[i])/sqrt(varY[i])
D[i]<-pow(PRes[i],2)
DNew[i]<-pow(PResNew[i],2)
}
Fit<-sum(D[1:N])
New<-sum(DNew[1:N])
# Prediction for new data
for (j in 1:M){
etax[j]<-beta.0+beta.1*MV_Tx[j]
log(mux[j])<-max(-20,min(20,etax[j]))
px[j]<-size/(size+mux[j])
prediction.NBx[j]~dnegbin(px[j],size)
}
}"
inits1 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits2 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
inits3 <- list(beta.0=rnorm(1,0,0.1),beta.1=rnorm(1,0,0.1),size=runif(1,0.1,5))
params <- c("beta.0","beta.1","size","PRes","MV_T_true","Fit","New","prediction.NBx")
#jags.neg <- jags.model(
#  data = jags.data,
#  inits = inits,
#  textConnection(model.NB),
#  n.chains = 3,
#  n.adapt=1000
#)
library(parallel)
cl <- makeCluster(3)
jags.neg <- run.jags(method="rjparallel", method.options=list(cl=cl),
data = jags.data,
inits = list(inits1,inits2,inits3),
model=model.NB,
n.chains = 3,
adapt=2000,
monitor=c(params),
burnin=20000,
sample=50000,
summarise=FALSE,
thin=5,
plots=FALSE
)
jagssamples.nb <- as.mcmc.list(jags.neg )
scale_fill_economist()+
)
Pred<-ggs(jagssamples.nb,family=c("New"))[,"value"]
Obs<-ggs(jagssamples.nb,family=c("Fit"))[,"value"]
sqrt(mean((Pred-Obs)^2))
# Dispersion parameter
require(scales)
Pres<-summary(as.mcmc.list(jags.neg, vars="PRes"),quantiles=0.5)$quantiles
Dipersion = sum(Pres^2)/(N-3)# beta.0, beta.1 and k, 3 parameters
Dipersion
jags.DIC <- jags.model(
data = jags.data,
inits = inits1,
textConnection(model.NB),
n.chains = 3,
n.adapt=2000
)
update(jags.DIC , 10000)
dicsamples.nb <- dic.samples(jags.DIC, params, n.iter = 25000,type="pD")
dicsamples.nb
975-25
995-5
citation(package = "rjags")
exp(2.19)
require(AMADA)
install_github("RafaelSdeSouza/AMADA")
require(devtools)
install_github("RafaelSdeSouza/AMADA")
require(AMADA)
require(AMADA)
corr<-Corr_MIC(SNIa,"pearson")
Fig1<-plotdendrogram(corr,"phylogram")
data("SNIa")
corr<-Corr_MIC(SNIa,"pearson")
Fig1<-plotdendrogram(corr,"phylogram")
install_github("RafaelSdeSouza/AMADA",dependencies=TRUE)
require(devtools)
install_github("RafaelSdeSouza/AMADA",dependencies=TRUE)
help("AMADA")
?AMADA
?"AMADA"
vignette("AMADA")
R CMD Rd2pdf AMADA
library(help="AMADA")
help("AMADA")
help(package="AMADA")
N = 10
M= 3
matrix(rnorm(N*M,mean=0,sd=1), N, M)
N = 100
M= 1000
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
M1
N = 10000
M= 1000
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"phylogram")
corr
Fig1<-plotdendrogram(corr,"fan")
N = 5000
M= 100
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"fan")
N = 5000
M= 500
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"fan")
N = 5000
M= 100
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"fan")
N = 50000
M= 100
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"fan")
N = 100000
M= 100
M1<-matrix(rnorm(N*M,mean=0,sd=1), N, M)
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"fan")
ptm <- proc.time()
corr<-Corr_MIC(M1,"pearson")
Fig1<-plotdendrogram(corr,"fan")
proc.time() - ptm
1.432+0.044
help(package="AMADA")
install.packages("GGally")
library("GGally", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
data(diamonds, package="ggplot2")
diamonds.samp <- diamonds[sample(1:dim(diamonds)[1],200),]
# Custom Example
pm <- ggpairs(
diamonds.samp[,1:3],
upper = list(continuous = "density", combo = "box"),
lower = list(continuous = "points", combo = "dot"),
color = "cut",
title = "Diamonds"
)
pm
pm <- ggpairs(
diamonds.samp[,1:3],
upper = list(continuous = "density", combo = "box"),
lower = list(continuous = "density", combo = "dot"),
color = "cut",
title = "Diamonds"
)
pm
ggpairs(
diamonds.samp[,1:3],
upper = list(continuous = "density", combo = "box"),
lower = list(continuous = "density"),
color = "cut",
title = "Diamonds"
)
ggpairs(
diamonds.samp[,1:3],
upper = list(continuous = "density"),
lower = list(continuous = "density"),
color = "cut",
title = "Diamonds"
)
ggpairs(
iris[,1:4],
upper = list(continuous = "density"),
lower = list(continuous = "density"),
color = "cut",
title = "Diamonds"
)
ggpairs(
iris[,1:4],
upper = list(continuous = "density"),
lower = list(continuous = "density")
)
ggpairs(
iris[,1:4],
upper = list(continuous = "cor"),
lower = list(continuous = "density")
)
pm <- ggpairs(
iris[,1:4],
upper = list(continuous = "cor"),
lower = list(continuous = "density"),
diag=list("density")
)
pm
ggpairs(
iris[,1:4],
upper = list(continuous = "cor"),
lower = list(continuous = "density"),
diag=list("bar'")
)
pm <- ggpairs(
iris[,1:4],
diag=list("bar"),
upper = list(continuous = "cor"),
lower = list(continuous = "density")
)
pm
pm <- ggpairs(
iris[,1:4],
diag=list("bar"),
upper = list(continuous = "cor"),
lower = list(continuous = "hist")
)
pm
pm <- ggpairs(
iris[,1:4],
diag=list("continuous"),
upper = list(continuous = "cor"),
lower = list(continuous = "density")
)
pm
install.packages("R1magic")
library(R1magic)#  Signal components
N <- 100
# Sparse components
K <- 4
#  Up to Measurements  > K LOG (N/K)
M <- 40
# Measurement Matrix (Random Sampling Sampling)
phi <- GaussianMatrix(N,M)
# R1magic generate random signal
xorg <- sparseSignal(N, K, nlev=1e-3)
y <- phi %*% xorg ;# generate measurement
T <- diag(N) ;# Do identity transform
p <- matrix(0, N, 1) ;# initial guess
# R1magic Convex Minimization ! (unoptimized-parameter)
ll <- solveL1(phi, y, T, p)
x1 <- ll$estimate
plot( 1:100, seq(0.011,1.1,0.011), type = “n”,xlab=””,ylab=””)
title(main=”Random Sparse Signal Recovery”,
xlab=”Signal Component”,ylab=”Spike Value”)
lines(1:100, xorg , col = “red”)
lines(1:100, x1, col = “blue”, cex = 1.5)
# shifted by 5 for clearity
library(R1magic)#  Signal components
N <- 100
# Sparse components
K <- 4
#  Up to Measurements  > K LOG (N/K)
M <- 40
# Measurement Matrix (Random Sampling Sampling)
phi <- GaussianMatrix(N,M)
# R1magic generate random signal
xorg <- sparseSignal(N, K, nlev=1e-3)
y <- phi %*% xorg ;# generate measurement
T <- diag(N) ;# Do identity transform
p <- matrix(0, N, 1) ;# initial guess
# R1magic Convex Minimization ! (unoptimized-parameter)
ll <- solveL1(phi, y, T, p)
x1 <- ll$estimate
plot( 1:100, seq(0.011,1.1,0.011), type = "n",xlab="",ylab="")
title(main="Random Sparse Signal Recovery",
xlab="Signal Component",ylab="Spike Value")
lines(1:100, xorg , col = "red")
lines(1:100, x1, col = “blue”, cex = 1.5)
# shifted by 5 for clearity
library(R1magic)#  Signal components
N <- 100
# Sparse components
K <- 4
#  Up to Measurements  > K LOG (N/K)
M <- 40
# Measurement Matrix (Random Sampling Sampling)
phi <- GaussianMatrix(N,M)
# R1magic generate random signal
xorg <- sparseSignal(N, K, nlev=1e-3)
y <- phi %*% xorg ;# generate measurement
T <- diag(N) ;# Do identity transform
p <- matrix(0, N, 1) ;# initial guess
# R1magic Convex Minimization ! (unoptimized-parameter)
ll <- solveL1(phi, y, T, p)
x1 <- ll$estimate
plot( 1:100, seq(0.011,1.1,0.011), type = "n",xlab="",ylab="")
title(main="Random Sparse Signal Recovery",
xlab="Signal Component",ylab="Spike Value")
lines(1:100, xorg , col = "red")
lines(1:100, x1, col = "blue", cex = 1.5)
xorg
x1
phi
y
diag(N)
matrix(0, N, 1)
setwd("~/Dropbox/artigos/Meusartigos/IAA-WGC/Github/Beta_regression")
#  JAGS script  Scape_Fraction.R
#  Copyright (C) 2015  Rafael S. de Souza
#
#This program is free software: you can redistribute it and/or modify
#it under the terms of the GNU General Public License version 3 as published by
#the Free Software Foundation.
#This program is distributed in the hope that it will be useful,
#but WITHOUT ANY WARRANTY; without even the implied warranty of
#MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#GNU General Public License for more details.
#  A copy of the GNU General Public License is available at
#  http://www.r-project.org/Licenses/
#
#  Required libraries
library(rjags)
library(ggmcmc)
library(ggplot2)
library(ggthemes)
library(pander)
library(Cairo)
library(plyr)
library(MASS)
library(scales)
library(plyr)
require(gdata)
require(runjags)
require(gdata)
require(caret)
require(pROC)
require(plyr)
#Read the  dataset
data.1= read.table(file="FiBY_escape_data_all.dat",header=FALSE)
colnames(data.1)<-c("redshift","fEsc","Mvir","Mstar","Mgas","QHI","sfr_gas",
"sfr_stars","ssfr_gas","ssfr_stars","baryon_fraction",
"spin","age_star_mean","age_star_max","age_star_min","NH_10")
trainIndex <- createDataPartition(data.1$redshift, p = .9,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
trainIndex <- createDataPartition(data.1$redshift, p = .25,
list = FALSE,
times = 1)
#data.2<-data.1[data.1$redshift==8.86815,]
data.2<-data.1[trainIndex,]
#data.2<-data.1[data.1$redshift==8.86815,]
#data.2<-data.1
N<-nrow(data.2)
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
fit=glm(Y~QHI+baryon_fraction,data=data.2,family=binomial("logit"))
logiGOF(fit,g=2)
library("LogisticDx", lib.loc="/Library/Frameworks/R.framework/Versions/3.1/Resources/library")
logiGOF(fit,g=2)
data.2<-data.1[data.1$redshift==8.86815,]
library(popbio)
logi.hist.plot(data.2$Mstar,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
library(popbio)
logi.hist.plot(data.2$Mstar,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
logi.hist.plot(data.2$Mhalo,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
data.2
data.2[1,]
logi.hist.plot(data.2$Mgas,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
logi.hist.plot(data.2$QHI,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
logi.hist.plot(data.2$baryon_fraction ,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
data.1$redshift
min(data.1$redshift)
data.2<-data.1[data.1$redshift<=8,]
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
# Prepare data for JAGS
data.2$Mstar<-(data.2$Mstar-mean(data.2$Mstar))/sd(data.2$Mstar)
data.2$Mgas<-(data.2$Mgas-mean(data.2$Mgas))/sd(data.2$Mgas)
data.2$Mvir<-(data.2$Mvir-mean(data.2$Mvir))/sd(data.2$Mvir)
data.2$sfr_gas<-(data.2$sfr_gas-mean(data.2$sfr_gas))/sd(data.2$sfr_gas)
data.2$baryon_fraction<-(data.2$baryon_fraction-mean(data.2$baryon_fraction))/sd(data.2$baryon_fraction)
data.2$QHI<-(data.2$QHI-mean(data.2$QHI))/sd(data.2$QHI)
data.2$ssfr_gas<-(data.2$ssfr_gas-mean(data.2$ssfr_gas))/sd(data.2$ssfr_gas)
data.2$age_star_mean<-(data.2$age_star_mean-mean(data.2$age_star_mean))/sd(data.2$age_star_mean)
data.2$spin<-(data.2$spin-mean(data.2$spin))/sd(data.2$spin)
data.2$NH_10<-(data.2$NH_10-mean(data.2$NH_10))/sd(data.2$NH_10)
logi.hist.plot(data.2$baryon_fraction ,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(sSFR[gas]),ylabel="Probability")
logi.hist.plot(data.2$baryon_fraction ,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(f[gas]),ylabel="Probability")
data.2<-data.1[data.1$redshift<=8,]
data.2$Y<-(data.2$fEsc*(N-1)+0.5)/N
data.2$Y[data.2$Y>=0.1]<-1
data.2$Y[data.2$Y<0.1]<-0
#data.2$Y<-as.factor(data.2$Y)
logi.hist.plot(data.2$baryon_fraction ,data.2$Y,boxp=F,type="hist",counts = T,col="gray",xlabel = expression(f[gas]),ylabel="Probability")
15*20
